{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入需要用的库\n",
    "import cifar10, cifar10_input\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data = './cifar10_data/cifar-10-batches-bin'\n",
    "images_train, labels_train = cifar10_input.inputs(eval_data = False, batch_size = batch_size)\n",
    "images_test, labels_test = cifar10_input.inputs(eval_data = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)  # stddev=stddev！！！\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(cons, shape):\n",
    "    initial = tf.constant(cons, shape=shape)  # 必须是 shape=shape\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def conv(x, W):\n",
    "    return tf.nn.conv2d(x, W, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_3x3(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_holder = tf.placeholder(tf.float32, [batch_size, 24, 24, 3])\n",
    "label_holder = tf.placeholder(tf.int32, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层\n",
    "weight1 = weight_variable([5, 5, 3, 64], 5e-2)\n",
    "bias1 = bias_variable(0.0, [64])\n",
    "\n",
    "conv1 = tf.nn.relu(conv(image_holder, weight1) + bias1)\n",
    "pool1 = max_pool_3x3(conv1)\n",
    "\n",
    "# 第二层\n",
    "weight2 = weight_variable([5, 5, 64, 64], 5e-2)\n",
    "bias2 = bias_variable(0.1, [64])\n",
    "\n",
    "conv2 = tf.nn.relu(conv(pool1, weight2) + bias2)\n",
    "pool2 = max_pool_3x3(conv2)\n",
    "\n",
    "reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "dim = reshape.get_shape()[1].value\n",
    "\n",
    "# 全连接层\n",
    "weight3 = weight_variable([dim, 384], 0.04)\n",
    "bias3 = bias_variable(0.1, [384])\n",
    "\n",
    "local3 = tf.nn.relu(tf.matmul(reshape, weight3) + bias3)\n",
    "\n",
    "# 全连接层\n",
    "weight4 = weight_variable([384, 192], 0.04)\n",
    "bias4 = bias_variable(0.1, [192])\n",
    "\n",
    "local4 = tf.nn.relu(tf.matmul(local3, weight4) + bias4)\n",
    "\n",
    "# 输出\n",
    "weight5 = weight_variable([192, 10], 1 / 192.0)\n",
    "bias5 = bias_variable(0.0, [10])\n",
    "logits = tf.matmul(local4, weight5) + bias5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-cfd0881e242f>:17: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 21:03:46.343130  6876 deprecation.py:323] From <ipython-input-38-cfd0881e242f>:17: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 21:03:46.349115  6876 queue_runner_impl.py:471] `tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 损失函数\n",
    "def loss(logits, labels):\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels,\n",
    "                                                                   name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "loss = loss(logits, label_holder)\n",
    "train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "top_k_op = tf.nn.in_top_k(logits, label_holder, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 21:04:39.062251  6876 queue_runner_impl.py:471] `tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0,loss=2.301417112350464,(250.668335078006 examples/sec; 0.5106348991394043 sec/batch)\n",
      "step 10,loss=2.031980514526367,(345.93557607612155 examples/sec; 0.3700110912322998 sec/batch)\n",
      "step 20,loss=1.798729658126831,(372.00654112873275 examples/sec; 0.34407997131347656 sec/batch)\n",
      "step 30,loss=1.7974029779434204,(331.63435100169005 examples/sec; 0.3859672546386719 sec/batch)\n",
      "step 40,loss=1.722352147102356,(453.5056832772439 examples/sec; 0.2822456359863281 sec/batch)\n",
      "step 50,loss=1.749363899230957,(321.65948620366123 examples/sec; 0.3979363441467285 sec/batch)\n",
      "step 60,loss=1.661386489868164,(329.9285241090095 examples/sec; 0.38796281814575195 sec/batch)\n",
      "step 70,loss=1.5997768640518188,(361.526555695547 examples/sec; 0.35405421257019043 sec/batch)\n",
      "step 80,loss=1.622209072113037,(406.1459375262413 examples/sec; 0.3151576519012451 sec/batch)\n",
      "step 90,loss=1.4217431545257568,(407.43556075323124 examples/sec; 0.3141601085662842 sec/batch)\n",
      "step 100,loss=1.4897708892822266,(361.52679914613367 examples/sec; 0.35405397415161133 sec/batch)\n",
      "step 110,loss=1.5041471719741821,(398.5776281081868 examples/sec; 0.32114195823669434 sec/batch)\n",
      "step 120,loss=1.6135276556015015,(456.7337741831475 examples/sec; 0.28025078773498535 sec/batch)\n",
      "step 130,loss=1.7036917209625244,(418.05148331051794 examples/sec; 0.3061823844909668 sec/batch)\n",
      "step 140,loss=1.4802565574645996,(348.75607189350575 examples/sec; 0.3670186996459961 sec/batch)\n",
      "step 150,loss=1.368361473083496,(385.41289440736955 examples/sec; 0.3321113586425781 sec/batch)\n",
      "step 160,loss=1.5983130931854248,(386.572632285352 examples/sec; 0.3311150074005127 sec/batch)\n",
      "step 170,loss=1.4090559482574463,(423.57180716142597 examples/sec; 0.30219197273254395 sec/batch)\n",
      "step 180,loss=1.448911190032959,(330.7784231322083 examples/sec; 0.3869659900665283 sec/batch)\n",
      "step 190,loss=1.3730435371398926,(365.6461383387365 examples/sec; 0.3500652313232422 sec/batch)\n",
      "step 200,loss=1.1820945739746094,(392.48277777940234 examples/sec; 0.3261289596557617 sec/batch)\n",
      "step 210,loss=1.3239898681640625,(451.9088793247851 examples/sec; 0.28324294090270996 sec/batch)\n",
      "step 220,loss=1.3994357585906982,(375.269662882079 examples/sec; 0.34108805656433105 sec/batch)\n",
      "step 230,loss=1.1831135749816895,(348.7558453386376 examples/sec; 0.3670189380645752 sec/batch)\n",
      "step 240,loss=1.3592300415039062,(357.4990041558431 examples/sec; 0.35804295539855957 sec/batch)\n",
      "step 250,loss=1.401185154914856,(429.23987246031976 examples/sec; 0.2982015609741211 sec/batch)\n",
      "step 260,loss=1.306150197982788,(360.5115472014354 examples/sec; 0.35505104064941406 sec/batch)\n",
      "step 270,loss=1.2837308645248413,(346.86849230987906 examples/sec; 0.3690159320831299 sec/batch)\n",
      "step 280,loss=1.4202079772949219,(332.49266079761685 examples/sec; 0.38497090339660645 sec/batch)\n",
      "step 290,loss=1.493354320526123,(406.14778104505695 examples/sec; 0.3151562213897705 sec/batch)\n",
      "step 300,loss=1.3810404539108276,(438.0277582190747 examples/sec; 0.2922189235687256 sec/batch)\n",
      "step 310,loss=1.333323359489441,(345.0061126391281 examples/sec; 0.37100791931152344 sec/batch)\n",
      "step 320,loss=1.4160842895507812,(324.0975979619803 examples/sec; 0.3949427604675293 sec/batch)\n",
      "step 330,loss=1.3825719356536865,(432.12786977347673 examples/sec; 0.29620862007141113 sec/batch)\n",
      "step 340,loss=1.1607211828231812,(450.3236584132214 examples/sec; 0.2842400074005127 sec/batch)\n",
      "step 350,loss=1.0500110387802124,(347.81028444376494 examples/sec; 0.36801671981811523 sec/batch)\n",
      "step 360,loss=1.154513955116272,(354.53568893206267 examples/sec; 0.3610355854034424 sec/batch)\n",
      "step 370,loss=1.160343050956726,(320.85478577046376 examples/sec; 0.39893436431884766 sec/batch)\n",
      "step 380,loss=1.239464282989502,(451.90925971754353 examples/sec; 0.28324270248413086 sec/batch)\n",
      "step 390,loss=1.2083685398101807,(301.27317793925613 examples/sec; 0.4248635768890381 sec/batch)\n",
      "step 400,loss=1.156062364578247,(342.24483210352685 examples/sec; 0.37400126457214355 sec/batch)\n",
      "step 410,loss=1.017869472503662,(376.3685456903502 examples/sec; 0.34009218215942383 sec/batch)\n",
      "step 420,loss=1.0053483247756958,(392.4836385621264 examples/sec; 0.3261282444000244 sec/batch)\n",
      "step 430,loss=1.2255380153656006,(420.7956847490334 examples/sec; 0.3041856288909912 sec/batch)\n",
      "step 440,loss=0.9861961603164673,(356.50479670688327 examples/sec; 0.3590414524078369 sec/batch)\n",
      "step 450,loss=1.08078932762146,(357.4985280437465 examples/sec; 0.3580434322357178 sec/batch)\n",
      "step 460,loss=1.1624605655670166,(315.3367525544307 examples/sec; 0.4059152603149414 sec/batch)\n",
      "step 470,loss=1.172868013381958,(436.53613672639517 examples/sec; 0.29321742057800293 sec/batch)\n",
      "step 480,loss=1.0826308727264404,(349.70610589067525 examples/sec; 0.36602163314819336 sec/batch)\n",
      "step 490,loss=0.9666866660118103,(357.5011466759715 examples/sec; 0.35804080963134766 sec/batch)\n",
      "step 500,loss=1.0878887176513672,(331.6335315788563 examples/sec; 0.3859682083129883 sec/batch)\n",
      "step 510,loss=1.0378895998001099,(429.2371269855991 examples/sec; 0.2982034683227539 sec/batch)\n",
      "step 520,loss=0.9474027156829834,(451.9096401109423 examples/sec; 0.28324246406555176 sec/batch)\n",
      "step 530,loss=0.924647331237793,(363.57553963655374 examples/sec; 0.35205888748168945 sec/batch)\n",
      "step 540,loss=1.11664617061615,(351.6217866681687 examples/sec; 0.3640275001525879 sec/batch)\n",
      "step 550,loss=0.9978849291801453,(367.74272369031223 examples/sec; 0.348069429397583 sec/batch)\n",
      "step 560,loss=1.2121843099594116,(451.9084989326671 examples/sec; 0.28324317932128906 sec/batch)\n",
      "step 570,loss=1.1507858037948608,(370.9308956093193 examples/sec; 0.3450777530670166 sec/batch)\n",
      "step 580,loss=0.9859101176261902,(345.0058909300755 examples/sec; 0.37100815773010254 sec/batch)\n",
      "step 590,loss=1.0164916515350342,(341.3348524373163 examples/sec; 0.3749983310699463 sec/batch)\n",
      "step 600,loss=0.951023280620575,(445.6321795574149 examples/sec; 0.2872323989868164 sec/batch)\n",
      "step 610,loss=1.0658925771713257,(430.67678398812745 examples/sec; 0.2972066402435303 sec/batch)\n",
      "step 620,loss=0.9227500557899475,(341.33637155482086 examples/sec; 0.3749966621398926 sec/batch)\n",
      "step 630,loss=1.1874706745147705,(363.5757858545171 examples/sec; 0.35205864906311035 sec/batch)\n",
      "step 640,loss=1.0110831260681152,(379.7119379866892 examples/sec; 0.3370976448059082 sec/batch)\n",
      "step 650,loss=1.0888285636901855,(420.7930462317426 examples/sec; 0.304187536239624 sec/batch)\n",
      "step 660,loss=0.7933070063591003,(354.5363913121001 examples/sec; 0.3610348701477051 sec/batch)\n",
      "step 670,loss=0.8127447366714478,(344.08140988090764 examples/sec; 0.37200498580932617 sec/batch)\n",
      "step 680,loss=1.0073102712631226,(403.591028652832 examples/sec; 0.317152738571167 sec/batch)\n",
      "step 690,loss=0.9353627562522888,(420.7940356718491 examples/sec; 0.3041868209838867 sec/batch)\n",
      "step 700,loss=0.9221198558807373,(416.69551017113463 examples/sec; 0.3071787357330322 sec/batch)\n",
      "step 710,loss=1.0465924739837646,(383.10924878260425 examples/sec; 0.3341083526611328 sec/batch)\n",
      "step 720,loss=0.8887148499488831,(366.6910585098245 examples/sec; 0.34906768798828125 sec/batch)\n",
      "step 730,loss=0.8679196834564209,(332.4924548797723 examples/sec; 0.38497114181518555 sec/batch)\n",
      "step 740,loss=0.9696208834648132,(423.5711387966898 examples/sec; 0.30219244956970215 sec/batch)\n",
      "step 750,loss=0.8482794165611267,(447.18485836157714 examples/sec; 0.28623509407043457 sec/batch)\n",
      "step 760,loss=0.8896936178207397,(341.33615453720665 examples/sec; 0.3749969005584717 sec/batch)\n",
      "step 770,loss=1.1025334596633911,(374.17561349586356 examples/sec; 0.3420853614807129 sec/batch)\n",
      "step 780,loss=0.9216310977935791,(461.6616178380098 examples/sec; 0.27725934982299805 sec/batch)\n",
      "step 790,loss=0.8408788442611694,(455.11226852146194 examples/sec; 0.2812492847442627 sec/batch)\n",
      "step 800,loss=0.8208346962928772,(410.0389073081614 examples/sec; 0.3121654987335205 sec/batch)\n",
      "step 810,loss=0.8576606512069702,(368.79815845097755 examples/sec; 0.3470733165740967 sec/batch)\n",
      "step 820,loss=1.0260264873504639,(388.9157088733221 examples/sec; 0.3291201591491699 sec/batch)\n",
      "step 830,loss=0.8621176481246948,(448.74801964267056 examples/sec; 0.28523802757263184 sec/batch)\n",
      "step 840,loss=1.0171260833740234,(439.52852873996085 examples/sec; 0.29122114181518555 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 850,loss=0.8817932605743408,(364.6086421480273 examples/sec; 0.3510613441467285 sec/batch)\n",
      "step 860,loss=0.923652708530426,(375.2691382601639 examples/sec; 0.34108853340148926 sec/batch)\n",
      "step 870,loss=0.7483811378479004,(381.97071138340084 examples/sec; 0.33510422706604004 sec/batch)\n",
      "step 880,loss=0.9389533996582031,(402.32408290018765 examples/sec; 0.31815147399902344 sec/batch)\n",
      "step 890,loss=0.9198735952377319,(367.74272369031223 examples/sec; 0.348069429397583 sec/batch)\n",
      "step 900,loss=0.7090661525726318,(350.6613299334302 examples/sec; 0.3650245666503906 sec/batch)\n",
      "step 910,loss=0.7282440662384033,(339.52954807047723 examples/sec; 0.37699222564697266 sec/batch)\n",
      "step 920,loss=0.7978273630142212,(438.0277582190747 examples/sec; 0.2922189235687256 sec/batch)\n",
      "step 930,loss=0.7819561958312988,(341.33550348601966 examples/sec; 0.374997615814209 sec/batch)\n",
      "step 940,loss=0.7577551603317261,(332.4928667157165 examples/sec; 0.38497066497802734 sec/batch)\n",
      "step 950,loss=0.8617343902587891,(350.66110089645827 examples/sec; 0.3650248050689697 sec/batch)\n",
      "step 960,loss=0.9784307479858398,(273.06805556261986 examples/sec; 0.468747615814209 sec/batch)\n",
      "step 970,loss=0.8658771514892578,(357.4990041558431 examples/sec; 0.35804295539855957 sec/batch)\n",
      "step 980,loss=0.8782764673233032,(316.89448535943706 examples/sec; 0.40391993522644043 sec/batch)\n",
      "step 990,loss=0.68871009349823,(327.40403261167194 examples/sec; 0.39095425605773926 sec/batch)\n",
      "step 1000,loss=0.8097245097160339,(246.3388602367624 examples/sec; 0.5196094512939453 sec/batch)\n",
      "step 1010,loss=0.6964882612228394,(271.9117112727667 examples/sec; 0.47074103355407715 sec/batch)\n",
      "step 1020,loss=0.8764416575431824,(376.3701287958027 examples/sec; 0.3400907516479492 sec/batch)\n",
      "step 1030,loss=0.6816091537475586,(307.7742354528809 examples/sec; 0.41588926315307617 sec/batch)\n",
      "step 1040,loss=0.879551887512207,(353.55973533938374 examples/sec; 0.3620321750640869 sec/batch)\n",
      "step 1050,loss=0.6529979109764099,(335.973736431877 examples/sec; 0.3809821605682373 sec/batch)\n",
      "step 1060,loss=0.7642143368721008,(258.75404406431176 examples/sec; 0.494678258895874 sec/batch)\n",
      "step 1070,loss=0.8384301662445068,(357.49781387797935 examples/sec; 0.3580441474914551 sec/batch)\n",
      "step 1080,loss=0.8025155067443848,(391.2870769876624 examples/sec; 0.32712554931640625 sec/batch)\n",
      "step 1090,loss=0.9980847239494324,(331.6333267237806 examples/sec; 0.3859684467315674 sec/batch)\n",
      "step 1100,loss=0.7880358099937439,(265.1693649321309 examples/sec; 0.4827103614807129 sec/batch)\n",
      "step 1110,loss=0.6918274164199829,(348.7549391221085 examples/sec; 0.3670198917388916 sec/batch)\n",
      "step 1120,loss=0.7555402517318726,(353.55973533938374 examples/sec; 0.3620321750640869 sec/batch)\n",
      "step 1130,loss=0.7842216491699219,(383.1100689407136 examples/sec; 0.3341076374053955 sec/batch)\n",
      "step 1140,loss=0.7880372405052185,(427.8039947535591 examples/sec; 0.29920244216918945 sec/batch)\n",
      "step 1150,loss=0.7330982089042664,(275.4120565094696 examples/sec; 0.46475815773010254 sec/batch)\n",
      "step 1160,loss=0.7363966107368469,(292.350454014523 examples/sec; 0.43783068656921387 sec/batch)\n",
      "step 1170,loss=0.7788594961166382,(436.53720158719835 examples/sec; 0.2932167053222656 sec/batch)\n",
      "step 1180,loss=0.7556537985801697,(366.69155942173114 examples/sec; 0.34906721115112305 sec/batch)\n",
      "step 1190,loss=0.6853222846984863,(320.8551692813387 examples/sec; 0.39893388748168945 sec/batch)\n",
      "step 1200,loss=0.7740393877029419,(342.2457048036204 examples/sec; 0.37400031089782715 sec/batch)\n",
      "step 1210,loss=0.654677152633667,(276.00446443030444 examples/sec; 0.4637606143951416 sec/batch)\n",
      "step 1220,loss=0.5749132633209229,(280.8360527450086 examples/sec; 0.4557819366455078 sec/batch)\n",
      "step 1230,loss=0.7007483839988708,(345.9349073612287 examples/sec; 0.3700118064880371 sec/batch)\n",
      "step 1240,loss=0.5624861717224121,(407.4343239327701 examples/sec; 0.3141610622406006 sec/batch)\n",
      "step 1250,loss=0.897537112236023,(273.6501329331746 examples/sec; 0.46775054931640625 sec/batch)\n",
      "step 1260,loss=0.6210174560546875,(263.5365746144912 examples/sec; 0.4857010841369629 sec/batch)\n",
      "step 1270,loss=0.8800525069236755,(313.7937090567326 examples/sec; 0.4079113006591797 sec/batch)\n",
      "step 1280,loss=0.6029778718948364,(347.81050977180865 examples/sec; 0.36801648139953613 sec/batch)\n",
      "step 1290,loss=0.6429879665374756,(338.6343585215088 examples/sec; 0.3779888153076172 sec/batch)\n",
      "step 1300,loss=0.786209225654602,(335.0961289275594 examples/sec; 0.38197994232177734 sec/batch)\n",
      "step 1310,loss=0.9455809593200684,(333.35583891750656 examples/sec; 0.3839740753173828 sec/batch)\n",
      "step 1320,loss=0.7386491298675537,(274.82274891900096 examples/sec; 0.46575474739074707 sec/batch)\n",
      "step 1330,loss=0.8244919776916504,(368.798665136162 examples/sec; 0.3470728397369385 sec/batch)\n",
      "step 1340,loss=0.6812179088592529,(422.1785182925103 examples/sec; 0.3031892776489258 sec/batch)\n",
      "step 1350,loss=0.6636802554130554,(343.1603346777544 examples/sec; 0.3730034828186035 sec/batch)\n",
      "step 1360,loss=0.6341075301170349,(256.17174600357106 examples/sec; 0.4996647834777832 sec/batch)\n",
      "step 1370,loss=0.7598868608474731,(344.0805277939071 examples/sec; 0.3720059394836426 sec/batch)\n",
      "step 1380,loss=0.5367155075073242,(293.0182195272376 examples/sec; 0.43683290481567383 sec/batch)\n",
      "step 1390,loss=0.6125364303588867,(345.93557607612155 examples/sec; 0.3700110912322998 sec/batch)\n",
      "step 1400,loss=0.6116317510604858,(385.4120643599078 examples/sec; 0.33211207389831543 sec/batch)\n",
      "step 1410,loss=0.572062611579895,(259.2768888178429 examples/sec; 0.4936807155609131 sec/batch)\n",
      "step 1420,loss=0.48148393630981445,(251.15827805275123 examples/sec; 0.509638786315918 sec/batch)\n",
      "step 1430,loss=0.7273344993591309,(412.67668807669486 examples/sec; 0.31017017364501953 sec/batch)\n",
      "step 1440,loss=0.5891990065574646,(336.8551074368135 examples/sec; 0.37998533248901367 sec/batch)\n",
      "step 1450,loss=0.7141261696815491,(368.798665136162 examples/sec; 0.3470728397369385 sec/batch)\n",
      "step 1460,loss=0.7352201342582703,(347.8096084613855 examples/sec; 0.36801743507385254 sec/batch)\n",
      "step 1470,loss=0.5547206997871399,(323.2794998741496 examples/sec; 0.39594221115112305 sec/batch)\n",
      "step 1480,loss=0.8417925834655762,(319.2587325175709 examples/sec; 0.4009287357330322 sec/batch)\n",
      "step 1490,loss=0.7144086956977844,(346.8731986685137 examples/sec; 0.36901092529296875 sec/batch)\n",
      "step 1500,loss=0.6391019225120544,(398.57792401589944 examples/sec; 0.32114171981811523 sec/batch)\n",
      "step 1510,loss=0.6877135038375854,(325.7411403802562 examples/sec; 0.39295005798339844 sec/batch)\n",
      "step 1520,loss=0.5482598543167114,(277.19738824503736 examples/sec; 0.4617648124694824 sec/batch)\n",
      "step 1530,loss=0.6661267280578613,(317.67791548445695 examples/sec; 0.4029238224029541 sec/batch)\n",
      "step 1540,loss=0.5513163805007935,(326.57037032981805 examples/sec; 0.3919522762298584 sec/batch)\n",
      "step 1550,loss=0.5896591544151306,(378.59027035870355 examples/sec; 0.33809638023376465 sec/batch)\n",
      "step 1560,loss=0.6423066854476929,(358.4968572231782 examples/sec; 0.35704636573791504 sec/batch)\n",
      "step 1570,loss=0.5340601205825806,(330.7782193321972 examples/sec; 0.3869662284851074 sec/batch)\n",
      "step 1580,loss=0.622353196144104,(247.28720678826113 examples/sec; 0.5176167488098145 sec/batch)\n",
      "step 1590,loss=0.7091730833053589,(330.86037108410864 examples/sec; 0.3868701457977295 sec/batch)\n",
      "step 1600,loss=0.5632381439208984,(435.05675492797957 examples/sec; 0.29421448707580566 sec/batch)\n",
      "step 1610,loss=0.5676684379577637,(298.4695515653683 examples/sec; 0.42885446548461914 sec/batch)\n",
      "step 1620,loss=0.5853396654129028,(244.9280012263031 examples/sec; 0.5226025581359863 sec/batch)\n",
      "step 1630,loss=0.5676636695861816,(363.57480098466453 examples/sec; 0.35205960273742676 sec/batch)\n",
      "step 1640,loss=0.665115237236023,(350.6613299334302 examples/sec; 0.3650245666503906 sec/batch)\n",
      "step 1650,loss=0.5571059584617615,(362.54827508431106 examples/sec; 0.3530564308166504 sec/batch)\n",
      "step 1660,loss=0.6868282556533813,(327.4042322750613 examples/sec; 0.39095401763916016 sec/batch)\n",
      "step 1670,loss=0.5817240476608276,(312.2676911354561 examples/sec; 0.40990471839904785 sec/batch)\n",
      "step 1680,loss=0.5127478241920471,(294.3626213235576 examples/sec; 0.43483781814575195 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1690,loss=0.7003335952758789,(362.55047855339313 examples/sec; 0.3530542850494385 sec/batch)\n",
      "step 1700,loss=0.7494313716888428,(387.74133095865915 examples/sec; 0.33011698722839355 sec/batch)\n",
      "step 1710,loss=0.6891968846321106,(330.77883073298375 examples/sec; 0.3869655132293701 sec/batch)\n",
      "step 1720,loss=0.7045999765396118,(254.6476844493331 examples/sec; 0.5026552677154541 sec/batch)\n",
      "step 1730,loss=0.5874133706092834,(336.8557415086609 examples/sec; 0.37998461723327637 sec/batch)\n",
      "step 1740,loss=0.6209293007850647,(283.31591620909205 examples/sec; 0.45179247856140137 sec/batch)\n",
      "step 1750,loss=0.5591658353805542,(361.52704259704825 examples/sec; 0.3540537357330322 sec/batch)\n",
      "step 1760,loss=0.61259925365448,(350.6613299334302 examples/sec; 0.3650245666503906 sec/batch)\n",
      "step 1770,loss=0.5734780430793762,(349.706333681821 examples/sec; 0.36602139472961426 sec/batch)\n",
      "step 1780,loss=0.7780797481536865,(254.1428436853987 examples/sec; 0.5036537647247314 sec/batch)\n",
      "step 1790,loss=0.5065039992332458,(324.91611093862815 examples/sec; 0.3939478397369385 sec/batch)\n",
      "step 1800,loss=0.5660796761512756,(423.57047043406294 examples/sec; 0.30219292640686035 sec/batch)\n",
      "step 1810,loss=0.6371429562568665,(384.2567939265671 examples/sec; 0.3331105709075928 sec/batch)\n",
      "step 1820,loss=0.6809605360031128,(293.01646035057996 examples/sec; 0.43683552742004395 sec/batch)\n",
      "step 1830,loss=0.5163180828094482,(320.85593630583907 examples/sec; 0.39893293380737305 sec/batch)\n",
      "step 1840,loss=0.5219241976737976,(271.3363125171205 examples/sec; 0.4717392921447754 sec/batch)\n",
      "step 1850,loss=0.58772873878479,(347.8098337885533 examples/sec; 0.36801719665527344 sec/batch)\n",
      "step 1860,loss=0.5756831169128418,(336.85595286647384 examples/sec; 0.37998437881469727 sec/batch)\n",
      "step 1870,loss=0.624397873878479,(310.75572431597044 examples/sec; 0.4118990898132324 sec/batch)\n",
      "step 1880,loss=0.4488288164138794,(262.45938698797727 examples/sec; 0.48769450187683105 sec/batch)\n",
      "step 1890,loss=0.5705899596214294,(285.2043297733541 examples/sec; 0.44880104064941406 sec/batch)\n",
      "step 1900,loss=0.4817391633987427,(420.7933760445944 examples/sec; 0.3041872978210449 sec/batch)\n",
      "step 1910,loss=0.3845652937889099,(347.81050977180865 examples/sec; 0.36801648139953613 sec/batch)\n",
      "step 1920,loss=0.5888144373893738,(341.33572050280605 examples/sec; 0.3749973773956299 sec/batch)\n",
      "step 1930,loss=0.46968796849250793,(323.2794998741496 examples/sec; 0.39594221115112305 sec/batch)\n",
      "step 1940,loss=0.59660404920578,(243.99618783588787 examples/sec; 0.5245983600616455 sec/batch)\n",
      "step 1950,loss=0.46384406089782715,(337.7421772182478 examples/sec; 0.37898731231689453 sec/batch)\n",
      "step 1960,loss=0.44619476795196533,(337.7421772182478 examples/sec; 0.37898731231689453 sec/batch)\n",
      "step 1970,loss=0.42657971382141113,(399.820158313232 examples/sec; 0.3201439380645752 sec/batch)\n",
      "step 1980,loss=0.6625799536705017,(283.31561718814726 examples/sec; 0.45179295539855957 sec/batch)\n",
      "step 1990,loss=0.40722715854644775,(249.27759997065525 examples/sec; 0.5134837627410889 sec/batch)\n",
      "step 2000,loss=0.47178322076797485,(414.00627096555286 examples/sec; 0.3091740608215332 sec/batch)\n",
      "step 2010,loss=0.3264598548412323,(342.2459229793392 examples/sec; 0.37400007247924805 sec/batch)\n",
      "step 2020,loss=0.5609910488128662,(372.00602559074485 examples/sec; 0.34408044815063477 sec/batch)\n",
      "step 2030,loss=0.5325828790664673,(398.57644448172977 examples/sec; 0.32114291191101074 sec/batch)\n",
      "step 2040,loss=0.4992389678955078,(300.5664615941019 examples/sec; 0.42586255073547363 sec/batch)\n",
      "step 2050,loss=0.6941766142845154,(305.5766125887993 examples/sec; 0.4188802242279053 sec/batch)\n",
      "step 2060,loss=0.6575635075569153,(352.58728764971323 examples/sec; 0.36303067207336426 sec/batch)\n",
      "step 2070,loss=0.4880302846431732,(378.59027035870355 examples/sec; 0.33809638023376465 sec/batch)\n",
      "step 2080,loss=0.523277223110199,(246.81189560794456 examples/sec; 0.5186135768890381 sec/batch)\n",
      "step 2090,loss=0.5387862920761108,(317.67885537106946 examples/sec; 0.4029226303100586 sec/batch)\n",
      "step 2100,loss=0.592444121837616,(343.1603346777544 examples/sec; 0.3730034828186035 sec/batch)\n",
      "step 2110,loss=0.5108166337013245,(347.81050977180865 examples/sec; 0.36801648139953613 sec/batch)\n",
      "step 2120,loss=0.3744414150714874,(360.5113051162609 examples/sec; 0.35505127906799316 sec/batch)\n",
      "step 2130,loss=0.5378462672233582,(444.09281703608855 examples/sec; 0.28822803497314453 sec/batch)\n",
      "step 2140,loss=0.6228408813476562,(304.1277349045279 examples/sec; 0.42087578773498535 sec/batch)\n",
      "step 2150,loss=0.49353960156440735,(257.7147789120381 examples/sec; 0.4966731071472168 sec/batch)\n",
      "step 2160,loss=0.44649994373321533,(345.00566922130787 examples/sec; 0.37100839614868164 sec/batch)\n",
      "step 2170,loss=0.45479023456573486,(356.5057436459319 examples/sec; 0.3590404987335205 sec/batch)\n",
      "step 2180,loss=0.44685494899749756,(369.8614525478352 examples/sec; 0.34607553482055664 sec/batch)\n",
      "step 2190,loss=0.5105854272842407,(246.81155521311348 examples/sec; 0.5186142921447754 sec/batch)\n",
      "step 2200,loss=0.49256181716918945,(342.2452684530173 examples/sec; 0.37400078773498535 sec/batch)\n",
      "step 2210,loss=0.30605530738830566,(379.7095209770995 examples/sec; 0.3370997905731201 sec/batch)\n",
      "step 2220,loss=0.6002529859542847,(368.79815845097755 examples/sec; 0.3470733165740967 sec/batch)\n",
      "step 2230,loss=0.44740408658981323,(345.00478238908676 examples/sec; 0.37100934982299805 sec/batch)\n",
      "step 2240,loss=0.5172870755195618,(291.68651752848973 examples/sec; 0.4388272762298584 sec/batch)\n",
      "step 2250,loss=0.355733722448349,(248.72487981197995 examples/sec; 0.514624834060669 sec/batch)\n",
      "step 2260,loss=0.43402761220932007,(334.22455080500873 examples/sec; 0.38297605514526367 sec/batch)\n",
      "step 2270,loss=0.439931184053421,(386.57346733928864 examples/sec; 0.3311142921447754 sec/batch)\n",
      "step 2280,loss=0.4118579030036926,(380.8370299486491 examples/sec; 0.336101770401001 sec/batch)\n",
      "step 2290,loss=0.3906826376914978,(355.51798711218856 examples/sec; 0.36003804206848145 sec/batch)\n",
      "step 2300,loss=0.44776690006256104,(355.5177516869632 examples/sec; 0.36003828048706055 sec/batch)\n",
      "step 2310,loss=0.41179147362709045,(239.44426297212414 examples/sec; 0.5345711708068848 sec/batch)\n",
      "step 2320,loss=0.2761607766151428,(374.1743095799807 examples/sec; 0.3420865535736084 sec/batch)\n",
      "step 2330,loss=0.5418281555175781,(377.47653703991455 examples/sec; 0.3390939235687256 sec/batch)\n",
      "step 2340,loss=0.4408568739891052,(424.9749956463231 examples/sec; 0.3011941909790039 sec/batch)\n",
      "step 2350,loss=0.42612224817276,(269.62598955688844 examples/sec; 0.4747316837310791 sec/batch)\n",
      "step 2360,loss=0.3048241436481476,(270.76389007268 examples/sec; 0.4727365970611572 sec/batch)\n",
      "step 2370,loss=0.47374916076660156,(439.52744923547226 examples/sec; 0.29122185707092285 sec/batch)\n",
      "step 2380,loss=0.542656660079956,(358.49733599811424 examples/sec; 0.35704588890075684 sec/batch)\n",
      "step 2390,loss=0.498661071062088,(367.7422199024461 examples/sec; 0.3480699062347412 sec/batch)\n",
      "step 2400,loss=0.5769170522689819,(323.279889203348 examples/sec; 0.39594173431396484 sec/batch)\n",
      "step 2410,loss=0.6670275330543518,(289.0578550841996 examples/sec; 0.44281792640686035 sec/batch)\n",
      "step 2420,loss=0.4190598130226135,(360.5100946952655 examples/sec; 0.35505247116088867 sec/batch)\n",
      "step 2430,loss=0.37576204538345337,(345.93468445683897 examples/sec; 0.3700120449066162 sec/batch)\n",
      "step 2440,loss=0.5052748322486877,(435.05287690148424 examples/sec; 0.2942171096801758 sec/batch)\n",
      "step 2450,loss=0.38184475898742676,(279.0036975579488 examples/sec; 0.45877528190612793 sec/batch)\n",
      "step 2460,loss=0.4802172780036926,(303.40929356453745 examples/sec; 0.4218723773956299 sec/batch)\n",
      "step 2470,loss=0.4318494200706482,(430.6778204548153 examples/sec; 0.29720592498779297 sec/batch)\n",
      "step 2480,loss=0.5461828708648682,(336.8555301511132 examples/sec; 0.37998485565185547 sec/batch)\n",
      "step 2490,loss=0.5089097023010254,(356.50550691069816 examples/sec; 0.3590407371520996 sec/batch)\n",
      "step 2500,loss=0.6019167900085449,(362.5472957733163 examples/sec; 0.3530573844909668 sec/batch)\n",
      "step 2510,loss=0.37027978897094727,(348.7553922297844 examples/sec; 0.3670194149017334 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2520,loss=0.49410223960876465,(264.62329284329945 examples/sec; 0.4837064743041992 sec/batch)\n",
      "step 2530,loss=0.47274431586265564,(361.526555695547 examples/sec; 0.35405421257019043 sec/batch)\n",
      "step 2540,loss=0.3632986545562744,(426.385480029322 examples/sec; 0.3001978397369385 sec/batch)\n",
      "step 2550,loss=0.4290016293525696,(351.62201696181853 examples/sec; 0.3640272617340088 sec/batch)\n",
      "step 2560,loss=0.4195009469985962,(248.24368687510895 examples/sec; 0.5156223773956299 sec/batch)\n",
      "step 2570,loss=0.42601704597473145,(362.54827508431106 examples/sec; 0.3530564308166504 sec/batch)\n",
      "step 2580,loss=0.35602521896362305,(282.6917418893509 examples/sec; 0.4527900218963623 sec/batch)\n",
      "step 2590,loss=0.5489739179611206,(348.7567515598762 examples/sec; 0.3670179843902588 sec/batch)\n",
      "step 2600,loss=0.3559521436691284,(348.7558453386376 examples/sec; 0.3670189380645752 sec/batch)\n",
      "step 2610,loss=0.37680867314338684,(365.64638736915805 examples/sec; 0.3500649929046631 sec/batch)\n",
      "step 2620,loss=0.32289958000183105,(300.5666298659274 examples/sec; 0.42586231231689453 sec/batch)\n",
      "step 2630,loss=0.4629634618759155,(353.55973533938374 examples/sec; 0.3620321750640869 sec/batch)\n",
      "step 2640,loss=0.2343810647726059,(340.42926721626134 examples/sec; 0.3759958744049072 sec/batch)\n",
      "step 2650,loss=0.5152500867843628,(388.914581935826 examples/sec; 0.32912111282348633 sec/batch)\n",
      "step 2660,loss=0.26957571506500244,(294.3622985299181 examples/sec; 0.43483829498291016 sec/batch)\n",
      "step 2670,loss=0.5242656469345093,(290.3662371602385 examples/sec; 0.4408226013183594 sec/batch)\n",
      "step 2680,loss=0.39379674196243286,(358.49733599811424 examples/sec; 0.35704588890075684 sec/batch)\n",
      "step 2690,loss=0.5581268668174744,(376.3698649439691 examples/sec; 0.3400909900665283 sec/batch)\n",
      "step 2700,loss=0.4118523895740509,(357.4982899881737 examples/sec; 0.3580436706542969 sec/batch)\n",
      "step 2710,loss=0.33500850200653076,(378.5921391861626 examples/sec; 0.33809471130371094 sec/batch)\n",
      "step 2720,loss=0.29567772150039673,(379.7103266435438 examples/sec; 0.3370990753173828 sec/batch)\n",
      "step 2730,loss=0.3677021265029907,(267.9364244095372 examples/sec; 0.4777252674102783 sec/batch)\n",
      "step 2740,loss=0.40857842564582825,(334.10744915149286 examples/sec; 0.38311028480529785 sec/batch)\n",
      "step 2750,loss=0.38461732864379883,(402.32589188695 examples/sec; 0.31815004348754883 sec/batch)\n",
      "step 2760,loss=0.5920676589012146,(342.24461392919886 examples/sec; 0.37400150299072266 sec/batch)\n",
      "step 2770,loss=0.3906196057796478,(260.8579245778989 examples/sec; 0.4906885623931885 sec/batch)\n",
      "step 2780,loss=0.4345294237136841,(293.68904254591706 examples/sec; 0.4358351230621338 sec/batch)\n",
      "step 2790,loss=0.39191606640815735,(372.0062833595602 examples/sec; 0.34408020973205566 sec/batch)\n",
      "step 2800,loss=0.39999905228614807,(373.0876654106966 examples/sec; 0.34308290481567383 sec/batch)\n",
      "step 2810,loss=0.29772883653640747,(324.91650421978596 examples/sec; 0.3939473628997803 sec/batch)\n",
      "step 2820,loss=0.2467501312494278,(416.69551017113463 examples/sec; 0.3071787357330322 sec/batch)\n",
      "step 2830,loss=0.3820842504501343,(358.4970966104864 examples/sec; 0.35704612731933594 sec/batch)\n",
      "step 2840,loss=0.39031997323036194,(297.7772334779869 examples/sec; 0.4298515319824219 sec/batch)\n",
      "step 2850,loss=0.37607401609420776,(360.51033677881435 examples/sec; 0.35505223274230957 sec/batch)\n",
      "step 2860,loss=0.392833411693573,(432.1285654148023 examples/sec; 0.29620814323425293 sec/batch)\n",
      "step 2870,loss=0.43578386306762695,(350.6613299334302 examples/sec; 0.3650245666503906 sec/batch)\n",
      "step 2880,loss=0.28339117765426636,(279.6122569405564 examples/sec; 0.4577767848968506 sec/batch)\n",
      "step 2890,loss=0.3611431121826172,(305.5759168770259 examples/sec; 0.4188811779022217 sec/batch)\n",
      "step 2900,loss=0.43878060579299927,(361.5275294998609 examples/sec; 0.354053258895874 sec/batch)\n",
      "step 2910,loss=0.32520976662635803,(340.4299148149886 examples/sec; 0.3759951591491699 sec/batch)\n",
      "step 2920,loss=0.44467800855636597,(361.52679914613367 examples/sec; 0.35405397415161133 sec/batch)\n",
      "step 2930,loss=0.3126171827316284,(363.5752934189239 examples/sec; 0.35205912590026855 sec/batch)\n",
      "step 2940,loss=0.29067113995552063,(313.40536501531795 examples/sec; 0.408416748046875 sec/batch)\n",
      "step 2950,loss=0.351809024810791,(287.11916117515057 examples/sec; 0.44580793380737305 sec/batch)\n",
      "step 2960,loss=0.33603227138519287,(370.9308956093193 examples/sec; 0.3450777530670166 sec/batch)\n",
      "step 2970,loss=0.4278894364833832,(416.69551017113463 examples/sec; 0.3071787357330322 sec/batch)\n",
      "step 2980,loss=0.31870606541633606,(334.22413466806114 examples/sec; 0.3829765319824219 sec/batch)\n",
      "step 2990,loss=0.4996282458305359,(297.08828410461126 examples/sec; 0.4308483600616455 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "tf.train.start_queue_runners()\n",
    "\n",
    "max_steps = 3000\n",
    "for step in range(max_steps):\n",
    "    start_time = time.time()\n",
    "    image_batch, label_batch = sess.run([images_train, labels_train])\n",
    "    _, loss_value = sess.run([train_op, loss], feed_dict={image_holder: image_batch, label_holder: label_batch})\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        examples_per_sec = batch_size / duration\n",
    "        sec_per_batch = float(duration)\n",
    "\n",
    "        print('step {},loss={},({} examples/sec; {} sec/batch)'.format(step, loss_value, examples_per_sec, sec_per_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.8341574367088608\n"
     ]
    }
   ],
   "source": [
    "num_examples = 10000\n",
    "num_iter = int(math.ceil(num_examples / batch_size))  # 计算一共有多少组\n",
    "true_count = 0\n",
    "total_sample_count = num_iter * batch_size\n",
    "step = 0\n",
    "while step < num_iter:\n",
    "    image_batch, label_batch = sess.run([images_test, labels_test])\n",
    "    predictions = sess.run([top_k_op], feed_dict={image_holder: image_batch, label_holder: label_batch})\n",
    "    true_count += np.sum(predictions)\n",
    "    step += 1\n",
    "\n",
    "precision = true_count / total_sample_count\n",
    "print('precision = ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
